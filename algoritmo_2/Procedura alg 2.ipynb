{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from dict_stops import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función que estandariza los valores de los paraderos de subida \n",
    "# y bajada\n",
    "def update_vals(row,data = load_metro_dictionary()):\n",
    "    if row.par_subida in data:\n",
    "        row.par_subida = data[row.par_subida]\n",
    "    if row.par_bajada in data:\n",
    "        row.par_bajada = data[row.par_bajada]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función que estandariza los valores de los paraderos de subida \n",
    "# y bajada\n",
    "def add_vals(row,latlong,paradero,data = dict_latlong_stops):\n",
    "    stop_name = row[paradero]\n",
    "    if stop_name in data:\n",
    "        return data[stop_name][latlong]\n",
    "    else :\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_config(frame):\n",
    "    frame['tiempo_subida'] = pd.to_datetime(frame.tiempo_subida)\n",
    "    frame['tiempo_bajada'] = pd.to_datetime(frame.tiempo_bajada)\n",
    "    frame = frame.apply(update_vals, axis=1)\n",
    "    frame['weekday'] = frame.tiempo_subida.dt.dayofweek\n",
    "    frame['lat_subida'] = frame.apply(add_vals,args=('lat','par_subida'),axis=1)\n",
    "    frame['lat_bajada'] = frame.apply(add_vals,args=('lat','par_bajada'),axis=1)\n",
    "    frame['long_subida'] = frame.apply(add_vals,args=('long','par_subida'),axis=1)\n",
    "    frame['long_bajada'] = frame.apply(add_vals,args=('long','par_bajada'),axis=1)\n",
    "    frame = frame.sort_values(by=['id', 'tiempo_subida'])\n",
    "    frame['diferencia_tiempo'] = (frame['tiempo_subida']-frame['tiempo_subida'].shift()).fillna(0)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hour_to_seconds(an_hour):\n",
    "    return int(an_hour.hour*3600 + an_hour.minute *60 + an_hour.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame_config(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_id_period = frame_config(df_id_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dframe = frame[['id','tiempo_subida','lat_subida','long_subida','tiempo_bajada','lat_bajada','long_bajada']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_id_period = df_id_period[['id','tiempo_subida','lat_subida','long_subida','tiempo_bajada','lat_bajada','long_bajada']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    path_subway_dictionary = 'C:\\Users\\catalina\\Documents\\Datois\\Diccionario-EstacionesMetro.csv'\n",
    "    path_csv_sequences = 'C:\\Users\\catalina\\Documents\\sequences\\\\'\n",
    "else:\n",
    "    path_subway_dictionary = '/home/cata/Documentos/Datois/Diccionario-EstacionesMetro.csv'\n",
    "    path_csv_sequences = '/home/cata/Documentos/sequences/'\n",
    "\n",
    "# Función que carga las estaciones de metro\n",
    "# en un diccionario\n",
    "def load_metro_dictionary():\n",
    "    dict_metro = {}\n",
    "    with open(path_subway_dictionary,mode='r') as infile:\n",
    "        reader = csv.reader(infile,delimiter=';')\n",
    "        dict_metro = {rows[5]:rows[7] for rows in reader}\n",
    "    return dict_metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.read_csv('/home/cata/Documentos/Datois/etapas_2013_abril_allyearsids_10_100000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_id_period = pd.read_csv('/home/cata/Documentos/Datois/etapas_2013_septiembre_allyearsids_10_100000.csv')\n",
    "df_id_period['tiempo_subida'] = pd.to_datetime(df_id_period.tiempo_subida)\n",
    "df_id_period = df_id_period.sort_values(by=['id', 'tiempo_subida'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probar función delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sequence(id_user, mls, nvisitas, sequence):\n",
    "\tprofile = {'user_id':id_user,'mls':mls,'nvisitas':nvisitas,'sequence':sequence}\n",
    "\treturn profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buscar_locacion(mls,location):\n",
    "\ttry:\n",
    "\t\tindex_location = mls.index(location)\n",
    "\texcept ValueError:\n",
    "\t\tindex_location = -1\n",
    "\treturn index_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequences(ids,lat_subidas,long_subidas,t_subidas,lat_bajadas,long_bajadas,t_bajadas):\n",
    "    # se inicializan las variables con los valores de la primera transaccion\n",
    "    profiles= [] # arreglo de diccionarios\n",
    "    First = True\n",
    "    # inicializo para despues usarlas\n",
    "    last_id = -22\n",
    "    mls = []\n",
    "    nvisitas = []\n",
    "    sequence = []\n",
    "    times = []\n",
    "    counter = 0\n",
    "    for transaction in zip(ids,lat_subidas,long_subidas,t_subidas,lat_bajadas,long_bajadas,t_bajadas):\n",
    "        id_user = transaction[0]\n",
    "        lat_subida = transaction[1]\n",
    "        long_subida = transaction[2]\n",
    "        t_subida = transaction[3]\n",
    "        lat_bajada = transaction[4]\n",
    "        long_bajada = transaction[5]\n",
    "        t_bajada = transaction[6]\n",
    "        counter += 1\n",
    "        if (lat_subida!=lat_subida or t_subida != t_subida):\n",
    "            continue \n",
    "        par_subida = (lat_subida,long_subida)\n",
    "        par_bajada = (lat_bajada,long_bajada)\n",
    "        subida_3 = (lat_subida,long_subida,hour_to_seconds(t_subida))\n",
    "        if First:\n",
    "            last_id = id_user\n",
    "            mls = [par_subida]\n",
    "            sequence = [subida_3]\n",
    "            last_stop = par_subida\n",
    "            times.append(hour_to_seconds(t_subida))\n",
    "            nvisitas = [0]\n",
    "            counter = 1\n",
    "            First = False\n",
    "        if id_user!=last_id:       \n",
    "            profiles.append(create_sequence(last_id,mls,nvisitas,sequence))\n",
    "            last_id = id_user\n",
    "            mls = [par_subida]\n",
    "            sequence = [subida_3]\n",
    "            last_stop = par_subida\n",
    "            nvisitas = [0]\n",
    "            counter = 1\n",
    "\n",
    "        index_subida = buscar_locacion(mls,par_subida)\n",
    "        # si la subida no había sido visitada se debe agregar al mls\n",
    "        if (index_subida < 0):\n",
    "            mls.append(par_subida)\n",
    "            nvisitas.append(1)\n",
    "            index_subida = len(mls) - 1\n",
    "            sequence.append(subida_3)\n",
    "            times.append(hour_to_seconds(t_subida))\n",
    "            # si la bajada no se pudo calcular solo se considera la subida y se deja para calcular tpm en la proxima ronda \n",
    "            if (lat_bajada!=lat_bajada or t_bajada != t_bajada):\n",
    "                last_stop = par_subida\n",
    "                #print \"Iteración n°: \" + str(counter) + \" , no se pudo estimar la bajada\"\n",
    "            else:\n",
    "                bajada_3 = (lat_bajada,long_bajada,hour_to_seconds(t_bajada))\n",
    "                last_stop = par_bajada\n",
    "                sequence.append(bajada_3)\n",
    "                times.append(hour_to_seconds(t_bajada))\n",
    "                index_bajada = buscar_locacion(mls,par_bajada)\n",
    "                # si la bajada no se había visitado antes, agregar bajada y sumar nvisitas \n",
    "                if (index_bajada < 0):\n",
    "                    mls.append(par_bajada)\n",
    "                    index_bajada = len(mls)-1\n",
    "                    nvisitas.append(1)\n",
    "                # sumar nvisita \n",
    "                else:\n",
    "                    nvisitas[index_bajada] = nvisitas[index_bajada]+1\n",
    "        else:\n",
    "            nvisitas[index_subida] = nvisitas[index_subida]+1\n",
    "            \n",
    "            if(par_subida!=last_stop):\n",
    "                sequence.append(subida_3)\n",
    "                times.append(hour_to_seconds(t_subida))\n",
    "            # subida estaba de antes y no hay bajada\n",
    "            # REVISAR SI ESTO NO ES REDUNDANTE!\n",
    "            if (lat_bajada!=lat_bajada or t_bajada!=t_bajada):\n",
    "                last_stop = par_subida\n",
    "            # hay subida y bajada\n",
    "            else:\n",
    "                bajada_3 = (lat_bajada,long_bajada,hour_to_seconds(t_bajada))\n",
    "                sequence.append(bajada_3)\n",
    "                times.append(hour_to_seconds(t_bajada))\n",
    "                last_stop = par_bajada\n",
    "                index_bajada = buscar_locacion(mls,par_bajada)\n",
    "                # hay bajada pero no estaba antes\n",
    "                if (index_bajada<0):\n",
    "                    mls.append(par_bajada)\n",
    "                    index_bajada = len(mls) - 1\n",
    "                    nvisitas.append(1)\n",
    "                # subida y bajada estaban de antes\n",
    "                else:\n",
    "                    nvisitas[index_bajada] = nvisitas[index_bajada]+1\n",
    "    profiles.append(create_sequence(last_id,mls,nvisitas,sequence))\n",
    "\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profiles = get_sequences(dframe['id'],dframe['lat_subida'],dframe['long_subida'],dframe['tiempo_subida'],dframe['lat_bajada'],dframe['long_bajada'],dframe['tiempo_bajada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_tw2 = get_sequences(df_id_period['id'],df_id_period['lat_subida'],df_id_period['long_subida'],df_id_period['tiempo_subida'],df_id_period['lat_bajada'],df_id_period['long_bajada'],df_id_period['tiempo_bajada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete(sequence,i,c,sum_lat=0,sum_long=0,sum_temp=0):\n",
    "    n = len(sequence)\n",
    "    if sum_lat == 0:\n",
    "        for seq in sequence:\n",
    "            sum_lat += seq[0]\n",
    "            sum_long += seq[1]\n",
    "            sum_temp += seq[2]\n",
    "    lat_distance = (sum_lat/n-(sum_lat-sequence[i][0])/(n-1))**2\n",
    "    long_distance = (sum_long/n-(sum_long-sequence[i][1])/(n-1))**2\n",
    "    temporal_distance = (sum_temp/n-(sum_temp-sequence[i][2])/(n-1))**2\n",
    "    spatial_distance = lat_distance + long_distance\n",
    "    return ((1-c)*spatial_distance+c*temporal_distance)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert(sequence,pi,c,sum_lat=0,sum_long=0,sum_temp=0):\n",
    "    n = len(sequence)\n",
    "    if sum_lat == 0:\n",
    "        for seq in sequence:\n",
    "            sum_lat += seq[0]\n",
    "            sum_long += seq[1]\n",
    "            sum_temp += seq[2]\n",
    "    lat_distance = (sum_lat/n-(sum_lat+pi[0])/(n+1))**2\n",
    "    long_distance = (sum_long/n-(sum_long+pi[0])/(n+1))**2\n",
    "    temporal_distance = (sum_temp/n-(sum_temp+pi[0])/(n+1))**2\n",
    "    spatial_distance = lat_distance + long_distance\n",
    "    return ((1-c)*spatial_distance+c*temporal_distance)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace(sequence,pi,pj,c,sum_lat=0,sum_long=0,sum_temp=0):\n",
    "    n = len(sequence)\n",
    "    if sum_lat == 0:\n",
    "        for seq in sequence:\n",
    "            sum_lat += seq[0]\n",
    "            sum_long += seq[1]\n",
    "            sum_temp += seq[2]\n",
    "    sum_lat_plus_pj = sum_lat - pi[0] +pj[0]\n",
    "    sum_long_plus_pj = sum_long - pi[1] +pj[1]\n",
    "    sum_temp_plus_pj = sum_temp - pi[2] +pj[2]\n",
    "    lat_distance = (sum_lat/n-sum_lat_plus_pj/n)**2\n",
    "    long_distance = (sum_long/n-sum_long_plus_pj/n)**2\n",
    "    temporal_distance = (sum_temp/n-sum_temp_plus_pj/n)**2\n",
    "    spatial_distance = lat_distance + long_distance\n",
    "    return ((1-c)*spatial_distance+c*temporal_distance)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(a_tuple):\n",
    "\treturn a_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion que compara la similitud entre un perfil y una secuencia de transacciones\n",
    "# Se normaliza el calculo según el largo de la secuencia\n",
    "# get_simliarity: [[int]] [string] [string] int int-> int \n",
    "def get_similarity(sequence_a,sequence_b,c,sum_lat,sum_long,sum_temp):\n",
    "    length_sequence_a = len(sequence_a)\n",
    "    length_sequence_b = len(sequence_b)\n",
    "    D = np.zeros((length_sequence_a+1,length_sequence_b+1))\n",
    "    for i in range(length_sequence_a):\n",
    "        D[i+1,0] = D[i,0] + delete(sequence_a,i,c)\n",
    "    for j in range(length_sequence_b):\n",
    "        D[0,j+1] = D[0,j] + insert(sequence_a,sequence_b[j],c)\n",
    "    for i in range(1,length_sequence_a+1):\n",
    "        for j in range(1,length_sequence_b+1):\n",
    "            m1 = D[i-1,j-1] + replace(sequence_a,sequence_a[i-1],sequence_b[j-1],c,sum_lat,sum_long,sum_temp)\n",
    "            m2 = D[i-1,j] + delete(sequence_a,i-1,c,sum_lat,sum_long,sum_temp)\n",
    "            m3 = D[i,j-1] + insert(sequence_a,sequence_b[j-1],c,sum_lat,sum_long,sum_temp)\n",
    "            D[i,j] = min(m1,m2,m3)\n",
    "    return D[length_sequence_a,length_sequence_b]\n",
    "\n",
    "# Funcion que construye la matriz de identificacion en que cada indice corresponde\n",
    "# a la similitud entre la i-esima tpm y la j-esima secuencia, obtenidas a partir de un\n",
    "# perfil de usuario y un periodo de identificacion.\n",
    "# len(users_profiles) == len(users_sequences)\n",
    "# asume que los usuarios de users_profiles y users_sequences son los mismos\n",
    "# get_identification_matrix; get_profiles(...) get_sequences(...) -> [[int]]\n",
    "def get_identification_matrix(profiles_tw1,profiles_tw2,c):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    limit = min((len(profiles_tw1),len(profiles_tw2)))\n",
    "    identification_matrix = np.zeros((limit,limit))\n",
    "    for profile_i in profiles_tw1:\n",
    "        sequence_a = profile_i['sequence']\n",
    "        sum_lat = 0\n",
    "        sum_long = 0\n",
    "        sum_temp = 0\n",
    "        for seq in sequence_a:\n",
    "            sum_lat += seq[0]\n",
    "            sum_long += seq[1]\n",
    "            sum_temp += seq[2]\n",
    "        length_sequence_a = len(sequence_a)\n",
    "        D_0 = np.zeros((length_sequence_a+1,1))\n",
    "        for n in range(length_sequence_a):\n",
    "            D_0[n+1,0] = D_0[n,0] + delete(sequence_a,n,c)\n",
    "        for profile_j in profiles_tw2:\n",
    "            sequence_b = profile_j['sequence']\n",
    "            length_sequence_b = len(sequence_b)\n",
    "            D = np.zeros((length_sequence_a+1,length_sequence_b+1))\n",
    "            D[:,0] = D_0[:,0]\n",
    "            for s in range(length_sequence_b):\n",
    "                D[0,s+1] = D[0,s] + insert(sequence_a,sequence_b[s],c)\n",
    "            for r in range(1,length_sequence_a+1):\n",
    "                for t in range(1,length_sequence_b+1):\n",
    "                    m1 = D[r-1,t-1] + replace(sequence_a,sequence_a[r-1],sequence_b[t-1],c,sum_lat,sum_long,sum_temp)\n",
    "                    m2 = D[r-1,t] + delete(sequence_a,r-1,c,sum_lat,sum_long,sum_temp)\n",
    "                    m3 = D[r,t-1] + insert(sequence_a,sequence_b[t-1],c,sum_lat,sum_long,sum_temp)\n",
    "                    D[r,t] = min(m1,m2,m3)\n",
    "            identification_matrix[i,j] = D[length_sequence_a,length_sequence_b]\n",
    "            j += 1\n",
    "            if(j >= limit):\n",
    "                break\n",
    "        i += 1\n",
    "        j=0\n",
    "        if(i >= limit):\n",
    "            break\n",
    "    return identification_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.88629007339\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "iden_matrix = get_identification_matrix(profiles[:20],profiles_tw2[:20],0)\n",
    "print time.time()-init_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012225"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.89/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
